import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List

def analyze_course_data(course_df: pd.DataFrame) -> Dict:
    print("=== PH√ÇN T√çCH D·ªÆ LI·ªÜU M√îh·ªçc ===")
    
    print(f"üìä T·ªïng s·ªë records: {len(course_df):,}")
    print(f"üë• S·ªë sinh vi√™n unique: {course_df['student_id'].nunique():,}")
    print(f"üìö S·ªë m√¥n h·ªçc unique: {course_df['Course ID'].nunique():,}")
    print(f"üìÖ S·ªë semester unique: {course_df['Semester'].nunique():,}")
    
    print(f"\nüìä Ph√¢n b·ªë ƒëi·ªÉm Final Grade:")
    grade_dist = course_df['Final Grade'].value_counts().sort_index()
    for grade, count in grade_dist.items():
        percentage = (count / len(course_df)) * 100
        print(f"  {grade}: {count:,} ({percentage:.1f}%)")
    
    print(f"\nüìä Th·ªëng k√™ ƒëi·ªÉm s·ªë:")
    print(f"  ƒêi·ªÉm qu√° tr√¨nh - Trung b√¨nh: {course_df['Continuous Assessment Score'].mean():.2f}")
    print(f"  ƒêi·ªÉm thi - Trung b√¨nh: {course_df['Exam Score'].mean():.2f}")
    
    print(f"\nüìö Top 10 m√¥n h·ªçc ph·ªï bi·∫øn:")
    top_courses = course_df['Course ID'].value_counts().head(10)
    for course, count in top_courses.items():
        print(f"  {course}: {count:,} l∆∞·ª£t ƒëƒÉng k√Ω")
    
    print(f"\nüìÖ Ph√¢n b·ªë theo Relative Term:")
    term_dist = course_df['Relative Term'].value_counts().sort_index()
    for term, count in term_dist.items():
        print(f"  K·ª≥ {term}: {count:,} records")
    
    return {
        'total_records': len(course_df),
        'unique_students': course_df['student_id'].nunique(),
        'unique_courses': course_df['Course ID'].nunique(),
        'grade_distribution': grade_dist.to_dict(),
        'avg_continuous_score': course_df['Continuous Assessment Score'].mean(),
        'avg_exam_score': course_df['Exam Score'].mean()
    }

def analyze_performance_data(perf_df: pd.DataFrame) -> Dict:
    print("\n=== PH√ÇN T√çCH D·ªÆ LI·ªÜU PERFORMANCE ===")
    
    print(f"üìä T·ªïng s·ªë records: {len(perf_df):,}")
    print(f"üë• S·ªë sinh vi√™n unique: {perf_df['student_id'].nunique():,}")
    
    gpa_stats = perf_df['GPA'].describe()
    cpa_stats = perf_df['CPA'].describe()
    
    print(f"\nüìà Th·ªëng k√™ GPA:")
    print(f"  Trung b√¨nh: {gpa_stats['mean']:.3f}")
    print(f"  ƒê·ªô l·ªách chu·∫©n: {gpa_stats['std']:.3f}")
    print(f"  Min: {gpa_stats['min']:.3f}")
    print(f"  Max: {gpa_stats['max']:.3f}")
    
    print(f"\nüìà Th·ªëng k√™ CPA:")
    print(f"  Trung b√¨nh: {cpa_stats['mean']:.3f}")
    print(f"  ƒê·ªô l·ªách chu·∫©n: {cpa_stats['std']:.3f}")
    print(f"  Min: {cpa_stats['min']:.3f}")
    print(f"  Max: {cpa_stats['max']:.3f}")
    
    print(f"\n‚ö†Ô∏è Ph√¢n b·ªë Warning levels:")
    warning_dist = perf_df['Warning'].value_counts()
    for warning, count in warning_dist.items():
        percentage = (count / len(perf_df)) * 100
        print(f"  {warning}: {count:,} ({percentage:.1f}%)")
    
    print(f"\nüéì Ph√¢n b·ªë Level (nƒÉm h·ªçc):")
    level_dist = perf_df['Level'].value_counts()
    for level, count in level_dist.items():
        percentage = (count / len(perf_df)) * 100
        print(f"  {level}: {count:,} ({percentage:.1f}%)")
    
    return {
        'gpa_mean': gpa_stats['mean'],
        'gpa_std': gpa_stats['std'],
        'cpa_mean': cpa_stats['mean'],
        'cpa_std': cpa_stats['std'],
        'warning_distribution': warning_dist.to_dict()
    }

def analyze_student_trajectories(course_df: pd.DataFrame, perf_df: pd.DataFrame):
    print("\n=== PH√ÇN T√çCH QU√Å TR√åNH H·ªåC T·∫¨P SINH VI√äN ===")
    
    students_with_multiple_terms = perf_df.groupby('student_id').size()
    students_with_enough_data = students_with_multiple_terms[students_with_multiple_terms >= 3]
    
    print(f"üë• Sinh vi√™n c√≥ √≠t nh·∫•t 3 k·ª≥ h·ªçc: {len(students_with_enough_data):,}")
    print(f"üìä Trung b√¨nh s·ªë k·ª≥/sinh vi√™n: {students_with_multiple_terms.mean():.1f}")
    print(f"üìä Max s·ªë k·ª≥: {students_with_multiple_terms.max()}")
    
    sample_students = students_with_enough_data.head(5).index
    
    print(f"\nüìà Ph√¢n t√≠ch xu h∆∞·ªõng GPA c·ªßa 5 sinh vi√™n m·∫´u:")
    for student_id in sample_students:
        student_perf = perf_df[perf_df['student_id'] == student_id].sort_values('Relative Term')
        gpa_values = student_perf['GPA'].dropna()
        
        if len(gpa_values) >= 2:
            gpa_trend = gpa_values.iloc[-1] - gpa_values.iloc[0]
            print(f"  Sinh vi√™n {student_id}: {gpa_values.iloc[0]:.2f} ‚Üí {gpa_values.iloc[-1]:.2f} "
                  f"({gpa_trend:+.2f})")

def create_visualizations(course_df: pd.DataFrame, perf_df: pd.DataFrame):
    print("\n=== T·∫†O BI·ªÇU ƒê·ªí PH√ÇN T√çCH ===")
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    grade_mapping = {'A+': 4.0, 'A': 3.7, 'B+': 3.3, 'B': 3.0, 'C+': 2.3, 'C': 2.0,
                     'D+': 1.3, 'D': 1.0, 'F': 0.0, 'X': 0.0, 'W': 0.0}
    course_df['Grade_Numeric'] = course_df['Final Grade'].map(grade_mapping)
    
    grade_counts = course_df['Final Grade'].value_counts()
    axes[0,0].pie(grade_counts.values, labels=grade_counts.index, autopct='%1.1f%%')
    axes[0,0].set_title('Ph√¢n b·ªë Final Grade')
    
    axes[0,1].hist(perf_df['GPA'].dropna(), bins=30, alpha=0.7, edgecolor='black')
    axes[0,1].set_title('Ph√¢n b·ªë GPA')
    axes[0,1].set_xlabel('GPA')
    axes[0,1].set_ylabel('T·∫ßn su·∫•t')
    
    axes[0,2].hist(perf_df['CPA'].dropna(), bins=30, alpha=0.7, color='green', edgecolor='black')
    axes[0,2].set_title('Ph√¢n b·ªë CPA')
    axes[0,2].set_xlabel('CPA')
    axes[0,2].set_ylabel('T·∫ßn su·∫•t')
    
    term_counts = course_df['Relative Term'].value_counts().sort_index()
    axes[1,0].bar(term_counts.index, term_counts.values)
    axes[1,0].set_title('S·ªë l∆∞·ª£ng records theo Relative Term')
    axes[1,0].set_xlabel('Relative Term')
    axes[1,0].set_ylabel('S·ªë l∆∞·ª£ng records')
    
    warning_counts = perf_df['Warning'].value_counts()
    axes[1,1].bar(range(len(warning_counts)), warning_counts.values)
    axes[1,1].set_xticks(range(len(warning_counts)))
    axes[1,1].set_xticklabels(warning_counts.index, rotation=45)
    axes[1,1].set_title('Ph√¢n b·ªë Warning Level')
    axes[1,1].set_ylabel('S·ªë l∆∞·ª£ng')
    
    students_with_multiple_terms = perf_df.groupby('student_id').size()
    axes[1,2].hist(students_with_multiple_terms.values, bins=20, alpha=0.7, color='orange', edgecolor='black')
    axes[1,2].set_title('Ph√¢n b·ªë s·ªë k·ª≥ h·ªçc/sinh vi√™n')
    axes[1,2].set_xlabel('S·ªë k·ª≥ h·ªçc')
    axes[1,2].set_ylabel('S·ªë sinh vi√™n')
    
    plt.tight_layout()
    plt.savefig('data_analysis_plots.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("üíæ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì ph√¢n t√≠ch v√†o 'data_analysis_plots.png'")

def main():
    print("üîç B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH D·ªÆ LI·ªÜU SINH VI√äN")
    print("=" * 60)
    
    try:
        course_df = pd.read_csv('csv/ET1_K62_K63_K64.csv')
        perf_df = pd.read_csv('csv/ET1_K62_K63_K64_performance.csv')
        
        course_stats = analyze_course_data(course_df)
        perf_stats = analyze_performance_data(perf_df)
        analyze_student_trajectories(course_df, perf_df)
        
        create_visualizations(course_df, perf_df)
        
        print("\n" + "=" * 60)
        print("‚úÖ HO√ÄN TH√ÄNH PH√ÇN T√çCH D·ªÆ LI·ªÜU")
        
        return {
            'course_stats': course_stats,
            'performance_stats': perf_stats
        }
        
    except FileNotFoundError as e:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu: {e}")
        print("Vui l√≤ng ƒë·∫£m b·∫£o c√°c file CSV ƒë√£ ƒë∆∞·ª£c ƒë·∫∑t trong th∆∞ m·ª•c 'csv/'")
        return None
    except Exception as e:
        print(f"‚ùå L·ªói khi ph√¢n t√≠ch d·ªØ li·ªáu: {e}")
        return None

if __name__ == "__main__":
    main() 